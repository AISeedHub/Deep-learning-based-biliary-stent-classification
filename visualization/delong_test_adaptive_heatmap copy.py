# filepath: d:\GitHub_repo\delong_test_adaptive_heatmap.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import os
import torch
import torch.nn.functional as F
import timm
from PIL import Image
import torchvision.transforms as transforms
import traceback
from torch.utils.data import DataLoader
from torchvision import datasets
from tqdm import tqdm
import scipy.stats as stats

# Use non-interactive backend to avoid TclError
import matplotlib
matplotlib.use('Agg')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì • (ëª¨ë“  ì¼€ì´ìŠ¤)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëª¨ë¸ëª… ì„¤ì •
model_name = 'resnet50.a1_in1k'  # ResNet ëª¨ë¸

num_classes = 2  # ì´ì§„ë¶„ë¥˜
batch_size = 1   # ë°°ì¹˜ 1ë¡œ ê³ ì •

# ì—í­ ì„¤ì •
epochs = [100, 200, 300, 400, 500]

# ëª¨ë“  ì¼€ì´ìŠ¤ ì„¤ì •
case_configs = {
    'case1': {
        'ckpt_root': r'd://res/case1',
        'base_data_path': r"C:\Users\IE\Desktop\stent\additional_dataset\Bona UC vs others_labeling",
        'save_prefix': 'delong_test_res_case1_adaptive',
        'figure_title': "Identification of BonastentÂ® uncovered",
        'num_classes': 2
    },
    'case2': {
        'ckpt_root': r'd://res/case2',
        'base_data_path': r"C:\Users\IE\Desktop\stent\additional_dataset\EGIS vs others_labeling",
        'save_prefix': 'delong_test_res_case2_adaptive',
        'figure_title': "Identification of EGIS",
        'num_classes': 2
    },
    'case3': {
        'ckpt_root': r'd://res/case3',
        'base_data_path': r"C:\Users\IE\Desktop\stent\additional_dataset\Epic vs others_labeling",
        'save_prefix': 'delong_test_res_case3_adaptive',
        'figure_title': "Identification of Epicâ„¢",
        'num_classes': 2
    },
    'case4': {
        'ckpt_root': r'd://res/case4',
        'base_data_path': r"C:\Users\IE\Desktop\stent\additional_dataset\NITIS vs others_labeling",
        'save_prefix': 'delong_test_res_case4_adaptive',
        'figure_title': "Identification of NITI-S",
        'num_classes': 2
    },
    'case5': {
        'ckpt_root': r'd://res/case5',
        'base_data_path': r"C:\Users\IE\Desktop\stent\additional_dataset\S vs M_labeling",
        'save_prefix': 'delong_test_res_case5_adaptive',
        'figure_title': "Single vs Multiple stent",
        'num_classes': 2
    },
    'single': {
        'ckpt_root': r'd:\\\res\single',
        'base_data_path': r"C:\Users\IE\Desktop\stent\additional_dataset\add_single class_labeling",
        'save_prefix': 'delong_test_res_single_adaptive',
        'figure_title': "Classification of vendors (single stent)",
        'num_classes': 5
    }
}

# ë°ì´í„° ì „ì²˜ë¦¬
preprocess = transforms.Compose([
    transforms.Resize(1536, interpolation=transforms.InterpolationMode.BICUBIC,
                      antialias=True),
    transforms.CenterCrop((1536, 1536)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485, 0.456, 0.406),
                         std=(0.229, 0.224, 0.225))
])

plt.rcParams['axes.unicode_minus'] = False

def load_model(ckpt_path, model_name, num_classes=2):
    """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ì „ì²´ë¥¼ ë¡œë“œ (ë©€í‹°í´ë˜ìŠ¤ ì§€ì›)"""
    try:
        model = torch.load(ckpt_path, map_location='cpu')
        
        # timm ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
        if hasattr(model, 'patch_embed'):
            if hasattr(model.patch_embed, '_init_img_size') and not hasattr(model.patch_embed, 'strict_img_size'):
                model.patch_embed.strict_img_size = model.patch_embed._init_img_size
            if not hasattr(model.patch_embed, 'dynamic_img_pad'):
                model.patch_embed.dynamic_img_pad = False
        
        # VisionTransformerì˜ dynamic_img_size ì†ì„± ì²˜ë¦¬
        if not hasattr(model, 'dynamic_img_size'):
            model.dynamic_img_size = False
        
        # reg_token ì†ì„± ì²˜ë¦¬ (VisionTransformer í˜¸í™˜ì„±)
        if not hasattr(model, 'reg_token'):
            model.reg_token = None
        
        # strict_img_size ì†ì„± ì²˜ë¦¬
        if not hasattr(model, 'strict_img_size'):
            model.strict_img_size = False
        
        print(f"âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {ckpt_path}")
        return model.to(device).eval()
    except Exception as e:
        print(f"âŒ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {ckpt_path} - ì˜¤ë¥˜: {e}")
        return None

def inference_once(model, dataset_path):
    """ì¶”ë¡  ìˆ˜í–‰"""
    dataset = datasets.ImageFolder(root=dataset_path, transform=preprocess)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,
                       num_workers=0, pin_memory=True)
    
    y_true, y_pred, y_score = [], [], []
    with torch.no_grad():
        for imgs, labels in tqdm(loader, desc='Infer', leave=False):
            logits = model(imgs.to(device))
            probabilities = torch.softmax(logits, dim=1)
            preds = logits.argmax(1).cpu().numpy()
            probs = probabilities.cpu().numpy()
            
            y_true.append(labels.item())
            y_pred.append(int(preds[0]))
            y_score.append(probs[0])  # ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥ 
    
    return np.array(y_true), np.array(y_pred), np.array(y_score)

def delong_test_with_clip(y_true, y_score1, y_score2, min_var_diff=1e-8):
    """
    DeLong test êµ¬í˜„ (í´ë¦½ ë²„ì „)
    ë‘ ROC ì»¤ë¸Œ ê°„ì˜ í†µê³„ì  ìœ ì˜ì„± ê²€ì •
    var_diffê°€ ìŒìˆ˜ë‚˜ ë„ˆë¬´ ì‘ì€ ê°’ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ np.clip ì‚¬ìš©
    """
    # ë°°ì—´ ê¸¸ì´ ê²€ì¦
    if len(y_true) != len(y_score1) or len(y_true) != len(y_score2):
        raise ValueError(f"ë°°ì—´ ê¸¸ì´ ë¶ˆì¼ì¹˜: y_true={len(y_true)}, y_score1={len(y_score1)}, y_score2={len(y_score2)}")
    
    # í´ë˜ìŠ¤ 1ì˜ í™•ë¥ ë§Œ ì‚¬ìš©
    y_score1_binary = y_score1[:, 1]
    y_score2_binary = y_score2[:, 1]
    y_true_binary = (y_true == 1).astype(int)
    
    # ì–‘ì„± í´ë˜ìŠ¤ì™€ ìŒì„± í´ë˜ìŠ¤ ë¶„ë¦¬
    positive_indices = y_true_binary == 1
    negative_indices = y_true_binary == 0
    
    y_score1_pos = y_score1_binary[positive_indices]
    y_score1_neg = y_score1_binary[negative_indices]
    y_score2_pos = y_score2_binary[positive_indices]
    y_score2_neg = y_score2_binary[negative_indices]
    
    # DeLong í†µê³„ëŸ‰ ê³„ì‚°
    n_pos = len(y_score1_pos)
    n_neg = len(y_score1_neg)
    
    if n_pos == 0 or n_neg == 0:
        raise ValueError(f"ì–‘ì„± ë˜ëŠ” ìŒì„± ìƒ˜í”Œì´ ì—†ìŒ: n_pos={n_pos}, n_neg={n_neg}")
    
    # V10, V01 ê³„ì‚° (DeLong et al., 1988)
    V10_1 = np.mean(y_score1_pos)
    V01_1 = np.mean(y_score1_neg)
    V10_2 = np.mean(y_score2_pos)
    V01_2 = np.mean(y_score2_neg)
    
    # AUC ê³„ì‚°
    auc1 = V10_1 - V01_1
    auc2 = V10_2 - V01_2
    
    # ë¶„ì‚° ê³„ì‚°
    S10_1 = np.var(y_score1_pos) / n_pos
    S01_1 = np.var(y_score1_neg) / n_neg
    S10_2 = np.var(y_score2_pos) / n_pos
    S01_2 = np.var(y_score2_neg) / n_neg
    
    # ê³µë¶„ì‚° ê³„ì‚°
    try:
        S10_12 = np.cov(y_score1_pos, y_score2_pos)[0, 1] / n_pos
        S01_12 = np.cov(y_score1_neg, y_score2_neg)[0, 1] / n_neg
    except Exception as e:
        raise ValueError(f"ê³µë¶„ì‚° ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    # í†µê³„ëŸ‰ ê³„ì‚° (ë” ë†’ì€ ì •ë°€ë„ ì‚¬ìš©)
    var_diff = S10_1 + S01_1 + S10_2 + S01_2 - 2 * (S10_12 + S01_12)
    
    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ (300 ì—í­ ê´€ë ¨)
    if abs(auc1 - auc2) < 0.01:  # AUC ì°¨ì´ê°€ ì‘ì€ ê²½ìš°
        print(f"ğŸ” DeLong Debug - AUC1: {auc1:.6f}, AUC2: {auc2:.6f}, AUC_Diff: {auc1-auc2:.6f}")
        print(f"   ë¶„ì‚°: S10_1={S10_1:.8f}, S01_1={S01_1:.8f}, S10_2={S10_2:.8f}, S01_2={S01_2:.8f}")
        print(f"   ê³µë¶„ì‚°: S10_12={S10_12:.8f}, S01_12={S01_12:.8f}")
        print(f"   var_diff (ì›ë³¸): {var_diff:.8f}")
    
    # AUC ì°¨ì´ì˜ í¬ê¸°ì— ë”°ë¥¸ ì²˜ë¦¬
    auc_diff_abs = abs(auc1 - auc2)
    
    # 1. AUCê°€ ê±°ì˜ ë™ì¼í•œ ê²½ìš°
    if auc_diff_abs < 1e-10:
        print(f"âš ï¸  AUCê°€ ê±°ì˜ ë™ì¼í•¨: {auc1:.6f} vs {auc2:.6f} -> p-value = 1")
        return 0.0, 1.0, (auc1, auc2)
    
    # 2. AUC ì°¨ì´ê°€ ì •ë§ ë¯¸ë¯¸í•œ ê²½ìš° (0.0035 ë¯¸ë§Œ) - p-value = 1
    if auc_diff_abs < 0.0035:
        print(f"âš ï¸  ë¯¸ë¯¸í•œ AUC ì°¨ì´: AUC_diff={auc_diff_abs:.6f} -> p-value = 1 (ì°¨ì´ê°€ ê±°ì˜ ì—†ìŒ)")
        return 0.0, 1.0, (auc1, auc2)
    
    # 3. ì¼ë°˜ì ì¸ ê²½ìš°: var_diffê°€ ìŒìˆ˜ì¸ ê²½ìš°ë§Œ í´ë¦½
    original_var_diff = var_diff
    if var_diff < 0:
        # ìŒìˆ˜ì¸ ê²½ìš° AUC ì°¨ì´ì˜ ì œê³±ì— ë¹„ë¡€í•˜ëŠ” ê°’ìœ¼ë¡œ ì„¤ì •
        adaptive_min_var = max(1e-6, (auc_diff_abs ** 2) * 0.1)
        var_diff = adaptive_min_var
        print(f"âš ï¸  ìŒìˆ˜ var_diff í´ë¦½: {original_var_diff:.8f} -> {var_diff:.8f} (ì ì‘ì  ìµœì†Œê°’: {adaptive_min_var:.8f})")
    
    z_stat = (auc1 - auc2) / np.sqrt(var_diff)
    p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))
    
    # ë§¤ìš° ì‘ì€ p-valueê°€ ë‚˜ì˜¨ ê²½ìš° ì¶”ê°€ ë””ë²„ê¹…
    if p_value < 1e-4:
        print(f"âš ï¸  ë§¤ìš° ì‘ì€ p-value ê°ì§€: {p_value:.2e}")
        print(f"   z_stat: {z_stat:.6f}, var_diff: {var_diff:.8f}")
        print(f"   AUC ì°¨ì´: {auc1-auc2:.6f}, sqrt(var_diff): {np.sqrt(var_diff):.8f}")
    
    return z_stat, p_value, (auc1, auc2)

def perform_delong_tests_for_case_by_set(case_name, config):
    """í•œ ì¼€ì´ìŠ¤ì— ëŒ€í•´ ê° ì„¸íŠ¸ë³„ë¡œ DeLong test ìˆ˜í–‰ í›„ ë©”íƒ€ë¶„ì„"""
    
    ckpt_root = config['ckpt_root']
    base_data_path = config['base_data_path']
    save_prefix = config['save_prefix']
    
    # ê° ì„¸íŠ¸ë³„ ê²°ê³¼ ì €ì¥
    set_results = {}
    
    # ê° ì„¸íŠ¸ë³„ë¡œ ì²˜ë¦¬
    for set_num in range(1, 6):
        
        dataset_path = os.path.join(base_data_path, f'set{set_num}', 'val')
        if not os.path.exists(dataset_path):
            continue
        
        # ê° ì—í­ë³„ ê²°ê³¼ ì €ì¥
        epoch_results = {}
        
        # ê° ì—í­ë³„ë¡œ ì¶”ë¡  ìˆ˜í–‰
        for epoch in epochs:
            # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì°¾ê¸°
            ckpt_path = os.path.join(ckpt_root, f'set{set_num}', f'{epoch}.pth')
            if not os.path.exists(ckpt_path):
                continue
            
            # ëª¨ë¸ ë¡œë“œ
            num_classes = config['num_classes']
            model = load_model(ckpt_path, model_name, num_classes)
            if model is None:
                continue
            
            # ì¶”ë¡ 
            y_true, y_pred, y_score = inference_once(model, dataset_path)
            
            # ROC AUC ê³„ì‚° (ë©€í‹°í´ë˜ìŠ¤ ì§€ì›)
            if num_classes == 2:
                # ì´ì§„ë¶„ë¥˜
                y_score_binary = y_score[:, 1]
                y_true_binary = (y_true == 1).astype(int)
                fpr, tpr, _ = roc_curve(y_true_binary, y_score_binary)
                roc_auc = auc(fpr, tpr)
            else:
                # ë©€í‹°í´ë˜ìŠ¤ (í´ë˜ìŠ¤ë³„ í‰ê·  AUC)
                y_true_one_hot = np.zeros((len(y_true), num_classes))
                for i, lbl in enumerate(y_true):
                    y_true_one_hot[i, lbl] = 1
                
                class_aucs = []
                for c in range(num_classes):
                    fpr, tpr, _ = roc_curve(y_true_one_hot[:, c], y_score[:, c])
                    roc_auc = auc(fpr, tpr)
                    class_aucs.append(roc_auc)
                
                roc_auc = np.mean(class_aucs)  # í´ë˜ìŠ¤ë³„ í‰ê·  AUC
            
            # ê²°ê³¼ ì €ì¥
            epoch_results[epoch] = {
                'y_true': y_true,
                'y_score': y_score,
                'auc': roc_auc
            }
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            del model
            torch.cuda.empty_cache()
        
        # ì„¸íŠ¸ë³„ ì—í­ ê°„ DeLong test ìˆ˜í–‰
        if len(epoch_results) >= 2:
            set_comparison_results = []
            epoch_list = sorted(epoch_results.keys())
            
            for i, epoch1 in enumerate(epoch_list):
                for j, epoch2 in enumerate(epoch_list[i+1:], i+1):
                    result1 = epoch_results[epoch1]
                    result2 = epoch_results[epoch2]
                    
                    auc1 = result1['auc']
                    auc2 = result2['auc']
                    auc_diff = auc1 - auc2
                    
                    # DeLong test ìˆ˜í–‰
                    y_true = result1['y_true']
                    y_score1 = result1['y_score']
                    y_score2 = result2['y_score']
                    
                    # ë°°ì—´ ê¸¸ì´ í™•ì¸
                    if len(y_true) != len(y_score1) or len(y_true) != len(y_score2):
                        raise ValueError(f'ë°°ì—´ ê¸¸ì´ ë¶ˆì¼ì¹˜ - y_true={len(y_true)}, y_score1={len(y_score1)}, y_score2={len(y_score2)}')
                    
                    # DeLong test ìˆ˜í–‰ (í´ë¦½ ë²„ì „)
                    z_stat, p_value, _ = delong_test_with_clip(y_true, y_score1, y_score2)
                    
                    if not np.isnan(p_value):
                        significance = "ìœ ì˜í•¨ (p<0.05)" if p_value < 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
                    else:
                        significance = "ê³„ì‚° ë¶ˆê°€"
                    
                    result = {
                        'Case': case_name.upper(),
                        'Set': set_num,
                        'Epoch1': epoch1,
                        'Epoch2': epoch2,
                        'AUC1': auc1,
                        'AUC2': auc2,
                        'AUC_Diff': auc_diff,
                        'Abs_AUC_Diff': abs(auc_diff),
                        'Z_Stat': z_stat,
                        'P_Value': p_value,
                        'Significance': significance,
                        'Sample_Size': len(y_true)
                    }
                    set_comparison_results.append(result)
            
            set_results[set_num] = set_comparison_results
    
    # ë©”íƒ€ë¶„ì„: ì„¸íŠ¸ë³„ ê²°ê³¼ë¥¼ í†µí•©
    if set_results:
        # ëª¨ë“  ì„¸íŠ¸ì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        all_set_results = []
        for set_num, results in set_results.items():
            all_set_results.extend(results)
        
        if not all_set_results:
            return None, set_results
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(all_set_results)
        
        # ë©”íƒ€ë¶„ì„: ê° ì—í­ ì¡°í•©ë³„ë¡œ ì„¸íŠ¸ë“¤ì˜ ê²°ê³¼ë¥¼ í†µí•©
        meta_analysis_results = []
        
        # ê³ ìœ í•œ ì—í­ ì¡°í•© ì°¾ê¸°
        epoch_pairs = df[['Epoch1', 'Epoch2']].drop_duplicates()
        
        for _, pair in epoch_pairs.iterrows():
            epoch1, epoch2 = pair['Epoch1'], pair['Epoch2']
            
            # í•´ë‹¹ ì—í­ ì¡°í•©ì˜ ëª¨ë“  ì„¸íŠ¸ ê²°ê³¼ í•„í„°ë§
            pair_results = df[(df['Epoch1'] == epoch1) & (df['Epoch2'] == epoch2)]
            
            if len(pair_results) == 0:
                continue
            
            # ìœ íš¨í•œ p-valueë§Œ í•„í„°ë§
            valid_results = pair_results[~pair_results['P_Value'].isna()]
            
            if len(valid_results) == 0:
                # ëª¨ë“  ê²°ê³¼ê°€ NaNì¸ ê²½ìš°
                meta_result = {
                    'Case': case_name.upper(),
                    'Epoch1': epoch1,
                    'Epoch2': epoch2,
                    'Mean_AUC1': np.nan,
                    'Mean_AUC2': np.nan,
                    'Mean_AUC_Diff': np.nan,
                    'Mean_Abs_AUC_Diff': np.nan,
                    'Meta_Z_Stat': np.nan,
                    'Meta_P_Value': np.nan,
                    'Meta_Significance': "ê³„ì‚° ë¶ˆê°€",
                    'Num_Sets': len(pair_results),
                    'Valid_Sets': 0,
                    'Sample_Size_Total': pair_results['Sample_Size'].sum()
                }
            else:
                # ë©”íƒ€ë¶„ì„ ìˆ˜í–‰ (Fisher's method ì‚¬ìš©)
                # p-valueë¥¼ z-scoreë¡œ ë³€í™˜
                z_scores = []
                weights = []
                
                # ë””ë²„ê¹…: 300-200 ì—í­ ì¡°í•© í™•ì¸
                debug_epochs = (epoch1 == 300 and epoch2 == 200) or (epoch1 == 200 and epoch2 == 300)
                if debug_epochs:
                    print(f"ğŸ” ë©”íƒ€ë¶„ì„ ë””ë²„ê¹… - {epoch1}-{epoch2} ì—í­ ì¡°í•©:")
                    print(f"   ìœ íš¨í•œ ì„¸íŠ¸ ìˆ˜: {len(valid_results)}")
                
                for _, row in valid_results.iterrows():
                    if not np.isnan(row['P_Value']) and row['P_Value'] > 0:
                        # p-valueë¥¼ z-scoreë¡œ ë³€í™˜
                        z_score = stats.norm.ppf(1 - row['P_Value'] / 2)  # ì–‘ì¸¡ ê²€ì •
                        if row['AUC_Diff'] < 0:  # ë°©í–¥ì„± ê³ ë ¤
                            z_score = -z_score
                        
                        z_scores.append(z_score)
                        weights.append(row['Sample_Size'])  # ìƒ˜í”Œ í¬ê¸°ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
                        
                        # ë””ë²„ê¹…: 300-200 ì—í­ ì¡°í•© í™•ì¸
                        if debug_epochs:
                            print(f"   Set{row['Set']}: p-value={row['P_Value']:.2e}, z-score={z_score:.6f}, weight={row['Sample_Size']}")
                
                if z_scores:
                    # ê°€ì¤‘ í‰ê·  z-score ê³„ì‚°
                    weighted_z = np.average(z_scores, weights=weights)
                    
                    # ë©”íƒ€ë¶„ì„ p-value ê³„ì‚°
                    meta_p_value = 2 * (1 - stats.norm.cdf(abs(weighted_z)))
                    
                    # ë””ë²„ê¹…: 300-200 ì—í­ ì¡°í•© í™•ì¸
                    if debug_epochs:
                        print(f"   ê°€ì¤‘í‰ê·  z-score: {weighted_z:.6f}")
                        print(f"   ë©”íƒ€ë¶„ì„ p-value: {meta_p_value:.2e}")
                        print(f"   AUC ì°¨ì´: {valid_results['AUC_Diff'].mean():.6f}")
                        print(f"   ì ˆëŒ€ AUC ì°¨ì´: {valid_results['Abs_AUC_Diff'].mean():.6f}")
                    
                    # AUC ì°¨ì´ê°€ ì •ë§ ë¯¸ë¯¸í•œ ê²½ìš°ì—ë§Œ ë©”íƒ€ë¶„ì„ p-valueë¥¼ 1ë¡œ ì„¤ì •
                    mean_auc_diff_abs = valid_results['Abs_AUC_Diff'].mean()
                    if mean_auc_diff_abs < 0.0035:  # 0.35% ë¯¸ë§Œì¼ ë•Œë§Œ
                        print(f"âš ï¸  ë©”íƒ€ë¶„ì„ì—ì„œ ë¯¸ë¯¸í•œ AUC ì°¨ì´ ê°ì§€: {mean_auc_diff_abs:.6f} -> p-value = 1")
                        meta_p_value = 1.0
                    meta_result = {
                        'Case': case_name.upper(),
                        'Epoch1': epoch1,
                        'Epoch2': epoch2,
                        'Mean_AUC1': valid_results['AUC1'].mean(),
                        'Mean_AUC2': valid_results['AUC2'].mean(),
                        'Mean_AUC_Diff': valid_results['AUC_Diff'].mean(),
                        'Mean_Abs_AUC_Diff': valid_results['Abs_AUC_Diff'].mean(),
                        'Meta_Z_Stat': weighted_z,
                        'Meta_P_Value': meta_p_value,
                        'Meta_Significance': "ìœ ì˜í•¨ (p<0.05)" if meta_p_value < 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ",
                        'Num_Sets': len(pair_results),
                        'Valid_Sets': len(valid_results),
                        'Sample_Size_Total': pair_results['Sample_Size'].sum()
                    }
                else:
                    meta_result = {
                        'Case': case_name.upper(),
                        'Epoch1': epoch1,
                        'Epoch2': epoch2,
                        'Mean_AUC1': np.nan,
                        'Mean_AUC2': np.nan,
                        'Mean_AUC_Diff': np.nan,
                        'Mean_Abs_AUC_Diff': np.nan,
                        'Meta_Z_Stat': np.nan,
                        'Meta_P_Value': np.nan,
                        'Meta_Significance': "ê³„ì‚° ë¶ˆê°€",
                        'Num_Sets': len(pair_results),
                        'Valid_Sets': 0,
                        'Sample_Size_Total': pair_results['Sample_Size'].sum()
                    }
            
            meta_analysis_results.append(meta_result)
        
        # ê²°ê³¼ ì €ì¥
        if meta_analysis_results:
            meta_df = pd.DataFrame(meta_analysis_results)
            
            # ì„¸íŠ¸ë³„ ìƒì„¸ ê²°ê³¼ ì €ì¥
            set_detail_df = pd.DataFrame(all_set_results)
            set_detail_filename = f'{save_prefix}_set_detail_results.csv'
            set_detail_df.to_csv(set_detail_filename, index=False)
            
            # ë©”íƒ€ë¶„ì„ ê²°ê³¼ ì €ì¥
            meta_filename = f'{save_prefix}_meta_analysis_results.csv'
            meta_df.to_csv(meta_filename, index=False)
            
            return meta_df, set_results
        else:
            return None, set_results
    else:
        return None, set_results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ì²˜ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì „ì²´ ê²°ê³¼ ì €ì¥
all_meta_results = []
all_set_results = {}

# ê° ì¼€ì´ìŠ¤ë³„ë¡œ ì„¸íŠ¸ë³„ DeLong test ìˆ˜í–‰
for case_name, config in case_configs.items():
    print(f"=== {case_name.upper()} í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì ì‘í˜• íˆíŠ¸ë§µ) ===")
    print(f"ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ: {config['ckpt_root']}")
    print(f"ë°ì´í„° ê²½ë¡œ: {config['base_data_path']}")
    print(f"ì €ì¥ ì ‘ë‘ì‚¬: {config['save_prefix']}")
    print("=" * 50)
    
    meta_df, set_results = perform_delong_tests_for_case_by_set(case_name, config)
    if meta_df is not None:
        all_meta_results.append(meta_df)
        print(f"âœ… {case_name.upper()} ë©”íƒ€ë¶„ì„ ì™„ë£Œ")
        print(f"ê²°ê³¼ íŒŒì¼: {config['save_prefix']}_meta_analysis_results.csv")
        print(f"ìƒì„¸ ê²°ê³¼ íŒŒì¼: {config['save_prefix']}_set_detail_results.csv")
    if set_results:
        all_set_results[case_name] = set_results
    
    print(f"=== {case_name.upper()} í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì ì‘í˜• íˆíŠ¸ë§µ) ===")
    print()

# ì „ì²´ ë©”íƒ€ë¶„ì„ ê²°ê³¼ í†µí•©
if all_meta_results:
    combined_meta_df = pd.concat(all_meta_results, ignore_index=True)
    combined_meta_df.to_csv('resnet_all_cases_meta_analysis_results_adaptive.csv', index=False)
    print("âœ… ì „ì²´ ì¼€ì´ìŠ¤ ë©”íƒ€ë¶„ì„ ê²°ê³¼ í†µí•© ì™„ë£Œ")
else:
    print("âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì‹œê°í™” í•¨ìˆ˜
def create_adaptive_heatmap_visualization(all_meta_results, case_configs):
    """ê° ì¼€ì´ìŠ¤ë³„ë¡œ ë©”íƒ€ë¶„ì„ ê²°ê³¼ë¥¼ ì ì‘í˜• íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”"""
    
    # ì„œë¸Œí”Œë¡¯ ì„¤ì • (6ê°œ ì¼€ì´ìŠ¤: 5ê°œ ê¸°ì¡´ + 1ê°œ single)
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle('Meta-Analysis Results: Adaptive Epoch-wise Comparison Heatmaps', fontsize=16, fontweight='bold')
    
    case_names = list(case_configs.keys())
    
    for idx, case_name in enumerate(case_names):
        # ì„œë¸Œí”Œë¡¯ ìœ„ì¹˜ ê³„ì‚°
        row = idx // 3
        col = idx % 3
        ax = axes[row, col]
        
        # í•´ë‹¹ ì¼€ì´ìŠ¤ì˜ ë©”íƒ€ë¶„ì„ ê²°ê³¼ í•„í„°ë§
        case_df = all_meta_results[all_meta_results['Case'] == case_name.upper()]
        
        if case_df.empty:
            ax.text(0.5, 0.5, f'No data for {case_name.upper()}', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title(case_configs[case_name]['figure_title'], fontsize=11, fontweight='bold')
            continue
        
        # ì—í­ ëª©ë¡ ì¶”ì¶œ
        all_epochs = sorted(set(case_df['Epoch1'].tolist() + case_df['Epoch2'].tolist()))
        
        # íˆíŠ¸ë§µ ë°ì´í„° ìƒì„± (ë©”íƒ€ë¶„ì„ p-value)
        heatmap_data = np.full((len(all_epochs), len(all_epochs)), np.nan)
        
        # ëŒ€ê°ì„ ì€ NaNìœ¼ë¡œ ì„¤ì • (ìê¸° ìì‹ ê³¼ì˜ ë¹„êµ)
        np.fill_diagonal(heatmap_data, np.nan)
        
        # ê° ì—í­ ì¡°í•©ì˜ ë©”íƒ€ë¶„ì„ ê²°ê³¼ë¥¼ íˆíŠ¸ë§µì— ì±„ìš°ê¸°
        for _, row_data in case_df.iterrows():
            epoch1_idx = all_epochs.index(row_data['Epoch1'])
            epoch2_idx = all_epochs.index(row_data['Epoch2'])
            
            # ë©”íƒ€ë¶„ì„ p-valueë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìœ ì˜ì„± íŒë‹¨ì„ ìœ„í•´)
            p_value = row_data['Meta_P_Value']
            if not np.isnan(p_value) and p_value > 0 and p_value <= 1:
                # p-valueë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                heatmap_value = p_value
            else:
                heatmap_value = np.nan
            
            # ëŒ€ê°ì„ ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ê°’ ì„¤ì •
            if epoch1_idx != epoch2_idx:
                heatmap_data[epoch1_idx, epoch2_idx] = heatmap_value
                heatmap_data[epoch2_idx, epoch1_idx] = heatmap_value  # ëŒ€ì¹­
        
        # ê° ì¼€ì´ìŠ¤ë³„ë¡œ ì ì‘í˜• ìƒ‰ìƒ ë²”ìœ„ ì„¤ì • (ì‹¤ì œ p-value ê¸°ì¤€)
        non_diagonal_data = heatmap_data[~np.eye(heatmap_data.shape[0], dtype=bool)]
        valid_data = non_diagonal_data[~np.isnan(non_diagonal_data)]
        
        if len(valid_data) > 0:
            # ê° ì¼€ì´ìŠ¤ì˜ ì‹¤ì œ p-value ë²”ìœ„ ì‚¬ìš©
            vmin = np.min(valid_data)
            vmax = np.max(valid_data)
        else:
            # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
            vmin = 0.001
            vmax = 0.05
        
        # ì¼ë°˜ì ì¸ ì»¬ëŸ¬ë§µ ì‚¬ìš© (viridis)
        im = ax.imshow(heatmap_data, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)
        
        # ì¶• ë ˆì´ë¸” ì„¤ì •
        ax.set_xticks(range(len(all_epochs)))
        ax.set_yticks(range(len(all_epochs)))
        ax.set_xticklabels(all_epochs)
        ax.set_yticklabels(all_epochs)
        
        # ì œëª© ì„¤ì •
        ax.set_title(case_configs[case_name]['figure_title'], fontsize=11, fontweight='bold')
        ax.set_xlabel('Epoch 1', fontsize=10)
        ax.set_ylabel('Epoch 2', fontsize=10)
        
        # ê°’ í‘œì‹œ
        for i in range(len(all_epochs)):
            for j in range(len(all_epochs)):
                if i == j:
                    # ëŒ€ê°ì„ : ìê¸° ìì‹ ê³¼ì˜ ë¹„êµ
                    text = ax.text(j, i, 'N/A',
                                 ha="center", va="center", color="black", fontsize=7, fontweight='normal')
                elif not np.isnan(heatmap_data[i, j]):
                    # ì‹¤ì œ ë¹„êµ ê²°ê³¼ (p-value ê·¸ëŒ€ë¡œ)
                    p_val = heatmap_data[i, j]
                    
                    # p-value ê°’ì— ë”°ë¥¸ ê¸€ì ìƒ‰ìƒ ì¡°ì •
                    if p_val < 0.04:
                        text_color = "white"  # 0.04 ë¯¸ë§Œì€ í°ìƒ‰ ê¸€ì”¨
                    else:
                        text_color = "black"  # ë‚˜ë¨¸ì§€ëŠ” ê²€ì •ê¸€ì”¨
                    font_weight = "normal"  # ëª¨ë“  ê¸€ì”¨ë¥¼ ì¼ë°˜ êµµê¸°ë¡œ
                    
                    # p-value í‘œì‹œ (ê³¼í•™ì  í‘œê¸°ë²• ì‚¬ìš©)
                    if p_val < 0.001:
                        text = f"{p_val:.2e}"
                    else:
                        text = f"{p_val:.3f}"
                    
                    text = ax.text(j, i, text,
                                 ha="center", va="center", color=text_color, 
                                 fontsize=8, fontweight="normal")
                else:
                    # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° (NaN)
                    text = ax.text(j, i, 'N/A',
                                 ha="center", va="center", color="red", fontsize=8, fontweight='normal')
        
        # ì»¬ëŸ¬ë°” ì¶”ê°€
        cbar = plt.colorbar(im, ax=ax, shrink=0.8)
        cbar.set_label('p-value', fontsize=9)
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    
    # ì €ì¥
    plt.savefig('all_cases_adaptive_heatmap123.png', dpi=300, bbox_inches='tight')
    plt.close()

# ì‹œê°í™” ì‹¤í–‰
if all_meta_results:
    create_adaptive_heatmap_visualization(combined_meta_df, case_configs)
    print("âœ… ì „ì²´ ì¼€ì´ìŠ¤ ì ì‘í˜• íˆíŠ¸ë§µ ì‹œê°í™” ì™„ë£Œ") 